epoch,step,train_loss,val_loss
0,0,,63.640499114990234
1,1,,63.57487869262695
2,2,,63.510128021240234
3,3,,63.44076156616211
4,4,,63.3844108581543
5,5,,63.3194465637207
6,6,,63.26682662963867
7,7,,63.20515060424805
8,8,,63.13767623901367
9,9,,63.09603500366211
10,10,,63.04217529296875
11,11,,62.972442626953125
12,12,,62.92353439331055
13,13,,62.8597412109375
14,14,,62.7972297668457
15,15,,62.74005126953125
16,16,,62.653175354003906
17,17,,62.62500762939453
18,18,,62.58637237548828
19,19,,62.55585479736328
20,20,,62.48344039916992
21,21,,62.42341232299805
22,22,,62.36603927612305
23,23,,62.30567169189453
24,24,,62.20815658569336
25,25,,62.15548324584961
26,26,,62.1267204284668
27,27,,62.0718994140625
28,28,,62.018470764160156
29,29,,61.95758819580078
30,30,,61.89324951171875
31,31,,61.8398551940918
32,32,,61.775630950927734
33,33,,61.71773147583008
34,34,,61.65444564819336
35,35,,61.572181701660156
36,36,,61.51131057739258
37,37,,61.45790481567383
38,38,,61.38690948486328
39,39,,61.3367919921875
40,40,,61.27368927001953
41,41,,61.20530319213867
42,42,,61.137264251708984
43,43,,61.0721321105957
44,44,,60.99406051635742
45,45,,60.92573928833008
46,46,,60.8572998046875
47,47,,60.79583740234375
48,48,,60.72735595703125
49,49,60.68848419189453,
49,49,,60.66114044189453
